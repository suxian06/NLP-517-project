{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4367fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95818cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gzip\n",
    "import csv\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424a3b0",
   "metadata": {},
   "source": [
    "# sbert script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221e5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1fae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "?models.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(to_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "train_batch_size = 16\n",
    "\n",
    "\n",
    "model_save_path = 'output/training_nli_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
